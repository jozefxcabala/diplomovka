[
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 17,
    "confidence_threshold": 0.3,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 17,
    "confidence_threshold": 0.3,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 17,
    "confidence_threshold": 0.3,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 17,
    "confidence_threshold": 0.45,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 17,
    "confidence_threshold": 0.45,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 17,
    "confidence_threshold": 0.45,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 17,
    "confidence_threshold": 0.6,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 17,
    "confidence_threshold": 0.6,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 17,
    "confidence_threshold": 0.6,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 19,
    "confidence_threshold": 0.3,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 19,
    "confidence_threshold": 0.3,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 19,
    "confidence_threshold": 0.3,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 19,
    "confidence_threshold": 0.45,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 19,
    "confidence_threshold": 0.45,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 19,
    "confidence_threshold": 0.45,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 19,
    "confidence_threshold": 0.6,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 19,
    "confidence_threshold": 0.6,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 19,
    "confidence_threshold": 0.6,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 21,
    "confidence_threshold": 0.3,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 21,
    "confidence_threshold": 0.3,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 21,
    "confidence_threshold": 0.3,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 21,
    "confidence_threshold": 0.45,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 21,
    "confidence_threshold": 0.45,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 21,
    "confidence_threshold": 0.45,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 21,
    "confidence_threshold": 0.6,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 21,
    "confidence_threshold": 0.6,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 21,
    "confidence_threshold": 0.6,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 23,
    "confidence_threshold": 0.3,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 23,
    "confidence_threshold": 0.3,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 23,
    "confidence_threshold": 0.3,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 23,
    "confidence_threshold": 0.45,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 23,
    "confidence_threshold": 0.45,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 23,
    "confidence_threshold": 0.45,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 23,
    "confidence_threshold": 0.6,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 23,
    "confidence_threshold": 0.6,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 23,
    "confidence_threshold": 0.6,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 24,
    "confidence_threshold": 0.3,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 24,
    "confidence_threshold": 0.3,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 24,
    "confidence_threshold": 0.3,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 24,
    "confidence_threshold": 0.45,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 24,
    "confidence_threshold": 0.45,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 24,
    "confidence_threshold": 0.45,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 24,
    "confidence_threshold": 0.6,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 24,
    "confidence_threshold": 0.6,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 24,
    "confidence_threshold": 0.6,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 25,
    "confidence_threshold": 0.3,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 25,
    "confidence_threshold": 0.3,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 25,
    "confidence_threshold": 0.3,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 25,
    "confidence_threshold": 0.45,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 25,
    "confidence_threshold": 0.45,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 25,
    "confidence_threshold": 0.45,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 25,
    "confidence_threshold": 0.6,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 25,
    "confidence_threshold": 0.6,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 25,
    "confidence_threshold": 0.6,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 26,
    "confidence_threshold": 0.3,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 26,
    "confidence_threshold": 0.3,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 26,
    "confidence_threshold": 0.3,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 26,
    "confidence_threshold": 0.45,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 26,
    "confidence_threshold": 0.45,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 26,
    "confidence_threshold": 0.45,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 26,
    "confidence_threshold": 0.6,
    "top_k": 1,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 26,
    "confidence_threshold": 0.6,
    "top_k": 3,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  },
  {
    "skip_frames": true,
    "num_of_skip_frames": 5,
    "dataset_path": "experiments/UBnormal",
    "model_path": "data/models/yolo11n.pt",
    "num_segments": 8,
    "categories": [
      "a person wearing a helmet and an orange vest is walking",
      "a person wearing a helmet and an orange vest is dancing",
      "a person wearing a helmet and an orange vest is standing in place",
      "a person wearing a helmet and an orange vest is jumping",
      "a person wearing a helmet and an orange vest is running",
      "a person wearing a helmet and an orange vest is fighting",
      "a person wearing a helmet and an orange vest have something in hand",
      "a person wearing a helmet and an orange vest is lying in the ground",
      "a person wearing a helmet and an orange vest is limping",
      "a person wearing a helmet and an orange vest fell to the ground",
      "a person wearing a helmet and an orange vest is sitting",
      "a person wearing a helmet and an orange vest is riding motocycle"
    ],
    "threshold": 26,
    "confidence_threshold": 0.6,
    "top_k": 5,
    "batch_size": 32,
    "frame_sample_rate": 4,
    "processing_mode": "sequential"
  }
]